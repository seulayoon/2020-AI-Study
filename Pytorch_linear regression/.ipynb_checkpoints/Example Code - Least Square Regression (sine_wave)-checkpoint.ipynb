{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "###     (preliminary: Linear Model)\n",
    "## 1. Library and Data, Preprocessing\n",
    "## 2. Compute W and b with 3 methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 3. [Advanced] Regularization: Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44d7a2390f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # for neural network models\n",
    "import torch.optim as optim # for optimization \n",
    "import torch.nn.init as init # for initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# simple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Advacnedplt.figure()\n",
    "\n",
    "# true data\n",
    "N = 40\n",
    "X = np.linspace(-np.pi/2, np.pi/2, N).reshape(N, 1) # 40 x 1\n",
    "y = np.sin(X)\n",
    "plt.plot(X, y)\n",
    "\n",
    "# add noise\n",
    "y += 0.1*np.random.randn(N, 1)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.title('sine wave data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_feature = 2\n",
    "\n",
    "PHI = np.ones(X.shape[0]).reshape(-1, 1) # 40 x 1\n",
    "for i in range(1, n_feature):\n",
    "    PHI = np.concatenate((PHI, np.power(X, i)), axis=1)\n",
    "print('PHI.shape: ', PHI.shape) # 40 x 2\n",
    "print('PHI[:3] \\n', PHI[:3])\n",
    "\n",
    "# shuffle\n",
    "idx = np.random.permutation(N)\n",
    "shuffle_X = X[idx]\n",
    "shuffle_PHI = PHI[idx]\n",
    "shuffle_y = y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Split train / test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = N-20\n",
    "\n",
    "# train data\n",
    "X_train = shuffle_X[:n]\n",
    "PHI_train = shuffle_PHI[:n]\n",
    "y_train = shuffle_y[:n]\n",
    "\n",
    "print(PHI_train)\n",
    "print(PHI_train.shape)\n",
    "\n",
    "# test data\n",
    "X_test = shuffle_X[:]\n",
    "PHI_test = shuffle_PHI[:]\n",
    "y_test = shuffle_y[:]\n",
    "\n",
    "print(PHI_test)\n",
    "print(PHI_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure()\n",
    "plt.scatter(X_train, y_train, label='train')\n",
    "plt.legend()\n",
    "plt.title('sine wave train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, y_test, label='test')\n",
    "plt.legend()\n",
    "plt.title('sine wave test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression (Formula)\n",
    "## method 1: compute W and b with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# compute W_ with PHI_train.\n",
    "W_ = np.linalg.inv(PHI_train.T @ PHI_train) @ PHI_train.T @ y_train\n",
    "print('[b, W] = W_')\n",
    "print('W_.shape: ', W_.shape)\n",
    "print('W_ \\n', W_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train, PHI_train @ W_, label='pred')\n",
    "plt.scatter(X_train, y_train, label='target')\n",
    "plt.title('train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, PHI_test @ W_, label='pred')\n",
    "plt.scatter(X_test, y_test, label='target')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression (Formula)\n",
    "## method 2: compute W and b with sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print('b: ', reg.intercept_)\n",
    "print('W: ', reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train, reg.predict(X_train), label='pred')\n",
    "plt.scatter(X_train, y_train, label='target')\n",
    "plt.legend()\n",
    "plt.title('train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, reg.predict(X_test), label='pred')\n",
    "plt.scatter(X_test, y_test, label='target')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression (Formula)\n",
    "## method 3: compute W and b with pytorch library (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "PHI_train = torch.tensor(PHI_train, dtype = torch.float) # if PHI_train is numpy.array\n",
    "label = torch.tensor(y_train, dtype=torch.float)\n",
    "\n",
    "# prepare model\n",
    "model = nn.Linear(n_feature, 1, bias = False) # train without bias. (PHI_train term have 1, have bias already.)\n",
    "\n",
    "# prepare optimziation and loss function \n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "# train the model \n",
    "for i in range(100):\n",
    "    optimizer.zero_grad() #그라디언트 0으로 초기화 (항상 해주어야 한다.)\n",
    "    output = model(PHI_train)\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        \n",
    "    param_list = list(model.parameters())\n",
    "\n",
    "\n",
    "print('W_ \\n', param_list[0][0][0])\n",
    "print('W_ \\n', param_list[0][0][1])\n",
    "\n",
    "PHI_test = torch.tensor(PHI_test, dtype = torch.float)\n",
    "\n",
    "y_train_pred = model(PHI_train)\n",
    "y_test_pred = model(PHI_test)\n",
    "\n",
    "y_train_pred = y_train_pred.detach().numpy()\n",
    "y_test_pred = y_test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> loss가 점점 줄어들고 있는것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train, y_train_pred, label='pred')\n",
    "plt.scatter(X_train, y_train, label='target')\n",
    "plt.legend()\n",
    "plt.title('train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, y_test_pred, label='pred')\n",
    "plt.scatter(X_test, y_test, label='target')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced: Regularization (Ridge, Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "PHI_train = PHI_train.clone().detach() # if PHI_train is torch.tensor\n",
    "label = label.clone().detach()\n",
    "\n",
    "# prepare model\n",
    "model = nn.Linear(n_feature, 1, bias = False) # train without bias. (PHI_train term have 1, have bias already.)\n",
    "\n",
    "# prepare optimziation and loss function \n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "#train model\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(PHI_train)\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    \n",
    "    # L1 regularization\n",
    "    regularization_loss = 0\n",
    "    regularization_coefficient = 1e-3\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        regularization_loss += torch.sum(torch.abs(param))\n",
    "    \n",
    "    regularization_loss = regularization * regularization_coefficient\n",
    "    loss = regularization_loss + loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        \n",
    "    param_list = list(model.parameters())\n",
    "\n",
    "\n",
    "print('b \\n', param_list[0][0][0])\n",
    "print('W_ \\n', param_list[0][0][1])\n",
    "\n",
    "PHI_test = PHI_test.clone().detach()\n",
    "\n",
    "y_train_pred = model(PHI_train)\n",
    "y_test_pred = model(PHI_test)\n",
    "\n",
    "y_train_pred = y_train_pred.detach().numpy()\n",
    "y_test_pred = y_test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train, y_train_pred, label='pred')\n",
    "plt.scatter(X_train, y_train, label='target')\n",
    "plt.legend()\n",
    "plt.title('train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, y_test_pred, label='pred')\n",
    "plt.scatter(X_test, y_test, label='target')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "PHI_train = PHI_train.clone().detach() # same with PHI_train = torch.tensor(PHI_train, dtype = torch.float)\n",
    "label = label.clone().detach()\n",
    "\n",
    "# prepare model \n",
    "model = nn.Linear(n_feature, 1, bias = False) # train without bias. (PHI_train term have 1, have bias already.)\n",
    "\n",
    "# prepare loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# L2 reguliarzation\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1, weight_decay = 0.01) #weight_decay : lambda값. \n",
    "\n",
    "# train the model\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(PHI_train)\n",
    "    \n",
    "    loss = loss_function(output, label)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        \n",
    "    param_list = list(model.parameters())\n",
    "\n",
    "\n",
    "print('b \\n', param_list[0][0][0])\n",
    "print('W_ \\n', param_list[0][0][1])\n",
    "\n",
    "PHI_test = PHI_test.clone().detach() # same with PHI_train = torch.tensor(PHI_train, dtype = torch.float)\n",
    "\n",
    "y_train_pred = model(PHI_train)\n",
    "y_test_pred = model(PHI_test)\n",
    "\n",
    "y_train_pred = y_train_pred.detach().numpy()\n",
    "y_test_pred = y_test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train, y_train_pred, label='pred')\n",
    "plt.scatter(X_train, y_train, label='target')\n",
    "plt.legend()\n",
    "plt.title('train data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_test, y_test_pred, label='pred')\n",
    "plt.scatter(X_test, y_test, label='target')\n",
    "plt.legend()\n",
    "plt.title('test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
